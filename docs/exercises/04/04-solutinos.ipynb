{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Database Management - Solutions\n",
    "\n",
    "This notebook contains solutions for the library database management exercises. We'll be working with bibliographic resources and publisher data to create a relational database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Creating the DataFrames\n",
    "\n",
    "In this exercise, we'll read the CSV files and create DataFrames with unique IDs for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the data.csv file with read_csv() function\n",
    "bibliographic_df = pd.read_csv('/path/to/your/folder/data.csv')\n",
    "\n",
    "# Step 2: Read the publishers.csv file\n",
    "publishers_df = pd.read_csv('/path/to/your/folder/publisher.csv')\n",
    "\n",
    "# You can decide to use .head() or not to display the first 5 rows of the DataFrame\n",
    "# printing a string like \"Bibliographic Resources DataFrame:\" before the DataFrame will make it easier to understand the output\n",
    "print(\"Bibliographic Resources DataFrame:\")\n",
    "print(bibliographic_df.head())\n",
    "print(\"\\nPublishers DataFrame:\")\n",
    "print(publishers_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 & 4: Add unique identifiers to each DataFrame\n",
    "\n",
    "# For bibliographic_df we create a new column called 'unique_id' and assign a unique identifier to each row\n",
    "# We use a for loop to iterate over the length of the DataFrame and assign a unique identifier to each row\n",
    "# The unique identifier is created by concatenating the string 'biblio-' with the row index\n",
    "# We use the range() function to generate a sequence of numbers from 0 to the length of the DataFrame\n",
    "# We convert the numbers to strings using the str() function and concatenate them with the string 'biblio-'\n",
    "# The resulting unique identifiers are stored in the 'unique_id' column of the DataFrame\n",
    "\n",
    "bibliographic_df['unique_id'] = ['biblio-' + str(i) for i in range(len(bibliographic_df))]\n",
    "\n",
    "# We repeat the same process for the publishers_df DataFrame, creating a new column called 'unique_id' and assigning unique identifiers to each row\n",
    "publishers_df['unique_id'] = ['publisher-' + str(i) for i in range(len(publishers_df))]\n",
    "\n",
    "# Step 5: Print the first five rows of each DataFrame with unique IDs\n",
    "print(\"Bibliographic Resources DataFrame with unique IDs:\")\n",
    "print(bibliographic_df.head())\n",
    "print(\"\\nPublishers DataFrame with unique IDs:\")\n",
    "print(publishers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Merging DataFrames\n",
    "\n",
    "Now, we'll merge the two DataFrames to maintain the relationship between resources and publishers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge the DataFrames on the publisher id field\n",
    "# The 'publisher' column in bibliographic_df corresponds to the 'id' column in publishers_df\n",
    "# We use the pd.merge() function to merge the two DataFrames based on these columns\n",
    "# The 'how' parameter is set to 'left' to keep all rows from the bibliographic_df DataFrame\n",
    "# The resulting merged DataFrame contains the columns from both DataFrames, with the 'publisher' column replaced by the 'name' column from publishers_df\n",
    "merged_df = pd.merge(\n",
    "    bibliographic_df,\n",
    "    publishers_df,\n",
    "    left_on='publisher',  # Column in bibliographic_df\n",
    "    right_on='id',        # Column in publishers_df\n",
    "    how='left'            # Keep all rows from bibliographic_df\n",
    ")\n",
    "\n",
    "# Step 2: Rename columns to avoid confusion\n",
    "# We rename the columns to avoid confusion, as both DataFrames have an 'id' column\n",
    "# We rename the 'id_x' column to 'bibliographic_id' and the 'id_y' column to 'publisher_id'\n",
    "merged_df = merged_df.rename(columns={\n",
    "    'id_x': 'bibliographic_id',  # From bibliographic_df\n",
    "    'id_y': 'publisher_id',      # From publishers_df\n",
    "    'name': 'publisher_name'     # To clarify this is the publisher's name\n",
    "})\n",
    "\n",
    "# Step 3: Print the first five rows of the newly created merged DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Connecting to SQLite and Creating the Database\n",
    "\n",
    "Finally, we'll create a SQLite database with appropriate tables based on our DataFrames and the UML diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Establish a connection to a new SQLite database\n",
    "# checking if the os path exists is just to make sure that the database file does not already exist\n",
    "# if it does, we remove it to start fresh\n",
    "if os.path.exists('library.db'):\n",
    "    os.remove('library.db')\n",
    "\n",
    "# creating a new connection to the SQLite database\n",
    "connection = sqlite3.connect('library.db')\n",
    "# creating a cursor object to execute SQL queries and operate on the db\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Step 2: Create the Publisher table\n",
    "# The Publisher table should be created first because BibliographicResource will reference it\n",
    "# Check SQL documentation for more information on the data types and operators used.\n",
    "# Note that the capitalization (\"TEXT\" vs \"text\") is not required, but it is a common convention to use uppercase for SQL keywords\n",
    "# to distinguish them from table and column names.\n",
    "# \"--\" is used for comments in SQL queries, this allows you to document your queries for future reference.\n",
    "cursor.execute('''\n",
    "CREATE TABLE Publisher (\n",
    "    id TEXT PRIMARY KEY,          -- Original ID from publishers.csv (e.g., 'crossref:15')\n",
    "    name TEXT NOT NULL,           -- Publisher's name\n",
    "    unique_id TEXT NOT NULL       -- Our manually created unique ID\n",
    ");\n",
    "''')\n",
    "\n",
    "# Step 3: Create the BibliographicResource table\n",
    "cursor.execute('''\n",
    "CREATE TABLE BibliographicResource (\n",
    "    id TEXT PRIMARY KEY,                -- Original ID from data.csv (e.g., 'doi:10.1037/e383822004-001')\n",
    "    title TEXT NOT NULL,                -- Title of the resource\n",
    "    type TEXT,                          -- Type of the resource (e.g., 'dataset')\n",
    "    publisher TEXT,                     -- Foreign key referencing Publisher.id\n",
    "    unique_id TEXT NOT NULL,            -- Our manually created unique ID\n",
    "    FOREIGN KEY (publisher) REFERENCES Publisher(id)\n",
    ");\n",
    "''')\n",
    "\n",
    "# Step 4: Insert the Publisher data\n",
    "# We use a for loop to iterate over the rows of the publishers_df DataFrame\n",
    "# For each row, we execute an INSERT query to add the data to the Publisher table\n",
    "for index, row in publishers_df.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Publisher (id, name, unique_id)\n",
    "    VALUES (?, ?, ?);\n",
    "    ''', (row['id'], row['name'], row['unique_id']))\n",
    "\n",
    "# Step 5: Insert the BibliographicResource data\n",
    "for index, row in bibliographic_df.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO BibliographicResource (id, title, type, publisher, unique_id)\n",
    "    VALUES (?, ?, ?, ?, ?);\n",
    "    ''', (row['id'], row['title'], row['type'], row['publisher'], row['unique_id']))\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "# It is important to commit the changes to the database after inserting data\n",
    "# This ensures that the changes are saved permanently to the database\n",
    "# (and this is why in this script we check if the file is already existing and remove it to start fresh)\n",
    "# Note that you have to comment that part of the script if you want to access to you db file later\n",
    "connection.commit()\n",
    "\n",
    "# Finally we close the connection\n",
    "connection.close()\n",
    "\n",
    "# It is a good practice to add a final print statement with something like \"job done\" or \"database created successfully\"\n",
    "# This will let you know that the script has completed successfully\n",
    "print(\"Database 'library.db' created successfully with Publisher and BibliographicResource tables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Let's verify that our database was created correctly by querying some data from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database previously created\n",
    "connection = sqlite3.connect('library.db')\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Query the Publisher table\n",
    "print(\"Publishers:\")\n",
    "#Â Here again the \"*\" means \"everything\" so we are selecting all the columns from the Publisher table\n",
    "# the \"LIMIT 5\" is used to limit the number of rows returned to 5\n",
    "# the \"cursor.fetchall()\" method is used to retrieve all the rows returned by the query\n",
    "# and then we iterate over them to print each row\n",
    "cursor.execute(\"SELECT * FROM Publisher LIMIT 5;\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "# Query the BibliographicResource table\n",
    "print(\"\\nBibliographic Resources:\")\n",
    "cursor.execute(\"SELECT * FROM BibliographicResource LIMIT 5;\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "# Query to join the tables (similar to our merged DataFrame)\n",
    "print(\"\\nJoined Data:\")\n",
    "# This query is slightly more complex as it involves joining the Publisher and BibliographicResource tables\n",
    "# We use the LEFT JOIN clause to keep all rows from the BibliographicResource table\n",
    "# We also use the AS keyword to alias the column names for clarity\n",
    "# The LIMIT 5 clause limits the number of rows returned to 5\n",
    "cursor.execute(\"\"\"\n",
    "SELECT b.id, b.title, b.type, p.name as publisher_name\n",
    "FROM BibliographicResource b\n",
    "LEFT JOIN Publisher p ON b.publisher = p.id\n",
    "LIMIT 5;\n",
    "\"\"\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n",
    "\n",
    "# Close the connection\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sandra)",
   "language": "python",
   "name": "sandra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
