{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "import select\n",
    "from sqlite3 import connect\n",
    "from pandas import read_sql_query\n",
    "from json import load \n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from rdflib import Graph, URIRef, Literal, RDF \n",
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Handler(object): #this is the first class, all the others derive from this one \n",
    "\n",
    "    #creating the class \n",
    "    def __init__(self, dbPathOrUrl : str):\n",
    "        self.dbPathOrUrl = dbPathOrUrl\n",
    "\n",
    "    #creating the methods \n",
    "    def getDbPathOrUrl(self): \n",
    "        return self.dbPathOrUrl \n",
    "\n",
    "    def setDbPathOrUrl(self, pathOrUrl : str): #: boolean \n",
    "        self.dbPathOrUrl = pathOrUrl\n",
    "        return True\n",
    "\n",
    "class UploadHandler(Handler):\n",
    "\n",
    "    def pushDataToDb(self, path: str):  #self implied \n",
    "        if path.lower().endswith(\".csv\"): \n",
    "            handler = JournalUploadHandler(self.dbPathOrUrl)\n",
    "            return handler.journalUpload(path) #calling the method after I called the subclass\n",
    "        elif path.lower().endswith(\".json\"): \n",
    "            handler = CategoryUploadHandler(self.dbPathOrUrl)\n",
    "            return handler.categoryUpload(path)\n",
    "        else: \n",
    "            return False \n",
    "\n",
    "#first case: the path is of the relational database the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CategoryUploadHandler(UploadHandler):\n",
    "\n",
    "\n",
    "\n",
    "    def categoryUpload(self, path: str):  \n",
    "        # Load JSON data\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                json_data = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file {path} was not found.\")\n",
    "            return\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {path}: {e}\")\n",
    "            return # Exit if JSON is invalid\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while opening or reading {path}: {e}\")\n",
    "            return\n",
    "\n",
    "        # Ensure json_data is a list\n",
    "        if not isinstance(json_data, list):\n",
    "            print(f\"Error: JSON data from {path} is not a list. Found type: {type(json_data)}\")\n",
    "            self._create_empty_tables()\n",
    "            return\n",
    "\n",
    "        item_data_rows = []\n",
    "        category_details_map = {} \n",
    "        area_details_map = {}     \n",
    "\n",
    "        # Changed to map (original_id, quartile) tuple to internal_id\n",
    "        category_composite_to_internal_id = {} \n",
    "        area_name_to_internal_id = {}         \n",
    "        \n",
    "        next_internal_category_idx = 0\n",
    "        next_internal_area_idx = 0\n",
    "        \n",
    "        # Set to keep track of processed item identifiers to ensure PK uniqueness\n",
    "        processed_item_identifiers = set()\n",
    "\n",
    "        for item_idx, item in enumerate(json_data):\n",
    "            if not isinstance(item, dict):\n",
    "                print(f\"Warning: Skipping item at index {item_idx} as it is not a dictionary.\")\n",
    "                continue\n",
    "\n",
    "            # --- Determine Item Main Identifier (Primary Key for item_data) ---\n",
    "            # This identifier will be taken from the first entry in the \"identifiers\" list in the JSON.\n",
    "            identifiers_from_json = item.get(\"identifiers\") # Use .get() for safer access\n",
    "            item_main_id = None\n",
    "\n",
    "            if not identifiers_from_json or not isinstance(identifiers_from_json, list) or len(identifiers_from_json) == 0:\n",
    "                print(f\"Warning: Item at index {item_idx} has no 'identifiers' list, it's not a list, or it's empty. Skipping item.\")\n",
    "                continue \n",
    "\n",
    "            potential_main_id = identifiers_from_json[0]\n",
    "\n",
    "            if not isinstance(potential_main_id, str) or not potential_main_id.strip():\n",
    "                print(f\"Warning: Item at index {item_idx} has an invalid or empty first identifier ('{potential_main_id}'). Skipping item.\")\n",
    "                continue \n",
    "            \n",
    "            # Check for duplicate identifiers (PK constraint)\n",
    "            if potential_main_id in processed_item_identifiers:\n",
    "                print(f\"Warning: Duplicate identifier '{potential_main_id}' found for item at index {item_idx}. Skipping item to maintain PK integrity.\")\n",
    "                continue \n",
    "            \n",
    "            item_main_id = potential_main_id\n",
    "            processed_item_identifiers.add(item_main_id)\n",
    "            # 'item_main_id' is now the actual identifier from the file (e.g., \"ABCD-1234\")\n",
    "\n",
    "        \n",
    "            item_associated_category_internal_ids = [] \n",
    "            for cat_info in item.get(\"categories\", []): \n",
    "                if not isinstance(cat_info, dict) or \"id\" not in cat_info: \n",
    "                    print(f\"Warning: Skipping invalid category data for item '{item_main_id}': {cat_info}\") \n",
    "                    continue \n",
    "                  \n",
    "                original_cat_json_id = cat_info[\"id\"] \n",
    "                quartile = cat_info.get(\"quartile\") # Capture quartile, which can be None\n",
    "\n",
    "                # Create a composite key for the category (original_id, quartile)\n",
    "                category_key = (original_cat_json_id, quartile)\n",
    "\n",
    "                # If this composite category (id + quartile) is not yet in our map, create a new internal ID\n",
    "                if category_key not in category_composite_to_internal_id:\n",
    "                    internal_cat_id = f\"cat-{next_internal_category_idx}\"\n",
    "                    category_composite_to_internal_id[category_key] = internal_cat_id\n",
    "                    \n",
    "                    category_details_map[internal_cat_id] = {\n",
    "                        \"original_id\": original_cat_json_id,\n",
    "                        \"quartile\": quartile\n",
    "                    }\n",
    "                    next_internal_category_idx += 1\n",
    "                else:\n",
    "                    # If it exists, use the previously assigned internal ID\n",
    "                    internal_cat_id = category_composite_to_internal_id[category_key]\n",
    "                  \n",
    "                item_associated_category_internal_ids.append(internal_cat_id) \n",
    "\n",
    "            \n",
    "            item_associated_internal_area_id = None \n",
    "            areas_list_from_json = item.get(\"areas\", [])\n",
    "            if areas_list_from_json:\n",
    "                if isinstance(areas_list_from_json, list) and len(areas_list_from_json) > 0:\n",
    "                    first_area_name = areas_list_from_json[0]\n",
    "                    if not isinstance(first_area_name, str):\n",
    "                        print(f\"Warning: Skipping non-string area data for item '{item_main_id}': {first_area_name}\")\n",
    "                    else:\n",
    "                        if first_area_name not in area_name_to_internal_id:\n",
    "                            internal_area_id = f\"area-{next_internal_area_idx}\"\n",
    "                            area_name_to_internal_id[first_area_name] = internal_area_id\n",
    "                            \n",
    "                            area_details_map[internal_area_id] = {\"name\": first_area_name}\n",
    "                            next_internal_area_idx += 1\n",
    "                        else:\n",
    "                            internal_area_id = area_name_to_internal_id[first_area_name]\n",
    "                        item_associated_internal_area_id = internal_area_id\n",
    "                else:\n",
    "                    print(f\"Warning: 'areas' field for item '{item_main_id}' is not a non-empty list: {areas_list_from_json}\")\n",
    "\n",
    "            \n",
    "            \n",
    "            # 'identifier' (e.g., \"ABCD-1234\" from the file) is the Primary Key for this table.\n",
    "            current_item_row = {\"identifier\": item_main_id} \n",
    "            \n",
    "            for i in range(8): \n",
    "                col_name = f\"category_{i+1}\"\n",
    "                if i < len(item_associated_category_internal_ids):\n",
    "                    current_item_row[col_name] = item_associated_category_internal_ids[i]\n",
    "                else:\n",
    "                    current_item_row[col_name] = None \n",
    "            \n",
    "            current_item_row[\"area\"] = item_associated_internal_area_id \n",
    "            item_data_rows.append(current_item_row)\n",
    "\n",
    "        # Convert collected data to Pandas DataFrames\n",
    "        # Only create DataFrame if there are rows to avoid error with empty list\n",
    "        if item_data_rows:\n",
    "            item_data_df = pd.DataFrame(item_data_rows)\n",
    "        else:\n",
    "            # Define columns for empty DataFrame to match schema if no valid items were processed\n",
    "            item_data_cols = [\"identifier\"] + [f\"category_{i+1}\" for i in range(8)] + [\"area\"]\n",
    "            item_data_df = pd.DataFrame(columns=item_data_cols)\n",
    "        \n",
    "        categories_table_rows = []\n",
    "        for internal_id, details in category_details_map.items():\n",
    "            categories_table_rows.append({\n",
    "                \"id\": internal_id, \n",
    "                \"original_id\": details[\"original_id\"],\n",
    "                \"quartile\": details[\"quartile\"]\n",
    "            })\n",
    "        if categories_table_rows:\n",
    "            category_details_df = pd.DataFrame(categories_table_rows)\n",
    "        else:\n",
    "            category_details_df = pd.DataFrame(columns=[\"id\", \"original_id\", \"quartile\"])\n",
    "\n",
    "\n",
    "        areas_table_rows = []\n",
    "        for internal_id, details in area_details_map.items():\n",
    "            areas_table_rows.append({\n",
    "                \"id\": internal_id, \n",
    "                \"name\": details[\"name\"]\n",
    "            })\n",
    "        if areas_table_rows:\n",
    "            area_details_df = pd.DataFrame(areas_table_rows)\n",
    "        else:\n",
    "            area_details_df = pd.DataFrame(columns=[\"id\", \"name\"])\n",
    "\n",
    "\n",
    "        # Write DataFrames to SQLite database\n",
    "        try:\n",
    "            with sqlite3.connect(self.dbPathOrUrl) as con:\n",
    "                item_data_df.to_sql(\"item_data\", con, if_exists=\"replace\", index=False)\n",
    "                category_details_df.to_sql(\"categories\", con, if_exists=\"replace\", index=False)\n",
    "                area_details_df.to_sql(\"areas\", con, if_exists=\"replace\", index=False)\n",
    "            print(f\"Data successfully uploaded to {self.dbPathOrUrl}\")\n",
    "\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Database error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during database operation: {e}\")\n",
    "\n",
    "    def _create_empty_tables(self):\n",
    "        \"\"\"Helper method to create empty tables with the defined schema if input is problematic.\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.dbPathOrUrl) as con:\n",
    "                item_data_cols = [\"identifier\"] + [f\"category_{i+1}\" for i in range(8)] + [\"area\"]\n",
    "                pd.DataFrame(columns=item_data_cols)\\\n",
    "                  .to_sql(\"item_data\", con, if_exists=\"replace\", index=False)\n",
    "                \n",
    "                pd.DataFrame(columns=[\"id\", \"original_id\", \"quartile\"])\\\n",
    "                  .to_sql(\"categories\", con, if_exists=\"replace\", index=False)\n",
    "                \n",
    "                pd.DataFrame(columns=[\"id\", \"name\"])\\\n",
    "                  .to_sql(\"areas\", con, if_exists=\"replace\", index=False)\n",
    "                print(f\"Created empty tables in {self.dbPathOrUrl} due to invalid or empty JSON input.\")\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Database error while creating empty tables: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while creating empty tables: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CategoryQueryHandler:\n",
    "\n",
    "    def __init__(self, dbPathOrUrl):\n",
    "        \"\"\"\n",
    "        Initializes the CategoryQueryHandler with the path to the SQLite database.\n",
    "\n",
    "        Args:\n",
    "            dbPathOrUrl (str): The path or URL to the SQLite database file.\n",
    "        \"\"\"\n",
    "        self.dbPathOrUrl = dbPathOrUrl\n",
    "\n",
    "    def _execute_query(self, query: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Helper method to execute a SQL query and return the result as a Pandas DataFrame.\n",
    "        Handles database connection and common errors.\n",
    "\n",
    "        Args:\n",
    "            query (str): The SQL query string to execute.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the query results, or an empty DataFrame on error.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.dbPathOrUrl) as con:\n",
    "                df = pd.read_sql_query(query, con)\n",
    "                return df\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Database error during query execution: {e}\")\n",
    "            return pd.DataFrame()  # Return empty DataFrame on error\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during query execution: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getAllCategories(self):\n",
    "        \n",
    "        query = \"SELECT id, original_id, quartile FROM categories\"\n",
    "        df = self._execute_query(query)\n",
    "        return df[\"original_id\"].drop_duplicates()\n",
    "\n",
    "    def getAllAreas(self):\n",
    "        \n",
    "        query = \"SELECT id, name FROM areas\"\n",
    "        df = self._execute_query(query)\n",
    "        return df[\"name\"].drop_duplicates()\n",
    "\n",
    "    def getCategoriesWithQuartile(self, quartiles: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a DataFrame containing all the categories having specified quartiles, with no repetitions.\n",
    "        If the input collection of quartiles is empty, it returns all categories.\n",
    "\n",
    "        Args:\n",
    "            quartiles (list): A list of quartile values (e.g., [1, 2, \"Q3\"]).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame with columns 'id', 'original_id', 'quartile' for matching categories.\n",
    "        \"\"\"\n",
    "        if not quartiles:\n",
    "            return self.getAllCategories()\n",
    "        \n",
    "        # Ensure quartile values are properly formatted for the SQL IN clause (strings quoted, numbers not)\n",
    "        formatted_quartiles = []\n",
    "        for q in quartiles:\n",
    "            if isinstance(q, str):\n",
    "                formatted_quartiles.append(f\"'{q}'\")\n",
    "            elif pd.isna(q): # Handle NaN values in quartiles if they exist\n",
    "                formatted_quartiles.append('NULL')\n",
    "            else:\n",
    "                formatted_quartiles.append(str(q))\n",
    "\n",
    "        quartiles_str = \",\".join(formatted_quartiles)\n",
    "        \n",
    "        query = f\"SELECT id, original_id, quartile FROM categories WHERE quartile IN ({quartiles_str})\"\n",
    "        # Add handling for NULL quartiles if 'NULL' is in the input list\n",
    "        if 'NULL' in formatted_quartiles:\n",
    "            query += \" OR quartile IS NULL\"\n",
    "        \n",
    "        return self._execute_query(query)\n",
    "\n",
    "    def getCategoriesAssignedToAreas(self, areas: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a DataFrame containing all the categories assigned to particular areas specified as input,\n",
    "        with no repetitions. If the input collection of areas is empty, it considers all areas.\n",
    "\n",
    "        Args:\n",
    "            areas (list): A list of area names (e.g., [\"Area A\", \"Area B\"]).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame with columns 'id', 'original_id', 'quartile' for relevant categories.\n",
    "        \"\"\"\n",
    "        item_data_df = self._execute_query(\"SELECT * FROM item_data\")\n",
    "        categories_df = self._execute_query(\"SELECT id, original_id, quartile FROM categories\")\n",
    "        areas_df = self._execute_query(\"SELECT id, name FROM areas\")\n",
    "\n",
    "        if not areas:\n",
    "            # If no areas specified, get all categories that are linked to any item in item_data\n",
    "            all_cat_ids_in_items = set()\n",
    "            for i in range(1, 9):\n",
    "                col_name = f\"category_{i}\"\n",
    "                if col_name in item_data_df.columns:\n",
    "                    all_cat_ids_in_items.update(item_data_df[col_name].dropna().unique())\n",
    "            \n",
    "            if not all_cat_ids_in_items:\n",
    "                return pd.DataFrame(columns=[\"id\", \"original_id\", \"quartile\"])\n",
    "\n",
    "            return categories_df[categories_df['id'].isin(all_cat_ids_in_items)]\n",
    "        \n",
    "        else:\n",
    "            # Get internal area IDs for the given area names\n",
    "            target_area_ids = areas_df[areas_df['name'].isin(areas)]['id'].tolist()\n",
    "\n",
    "            if not target_area_ids:\n",
    "                return pd.DataFrame(columns=[\"id\", \"original_id\", \"quartile\"])\n",
    "\n",
    "            # Filter item_data to include only items assigned to the target areas\n",
    "            filtered_item_data_df = item_data_df[item_data_df['area'].isin(target_area_ids)]\n",
    "\n",
    "            if filtered_item_data_df.empty:\n",
    "                return pd.DataFrame(columns=[\"id\", \"original_id\", \"quartile\"])\n",
    "            \n",
    "            # Collect all unique category IDs from the filtered item_data\n",
    "            assigned_category_ids = set()\n",
    "            for i in range(1, 9):\n",
    "                col_name = f\"category_{i}\"\n",
    "                if col_name in filtered_item_data_df.columns:\n",
    "                    assigned_category_ids.update(filtered_item_data_df[col_name].dropna().unique())\n",
    "            \n",
    "            if not assigned_category_ids:\n",
    "                return pd.DataFrame(columns=[\"id\", \"original_id\", \"quartile\"])\n",
    "\n",
    "            # Filter the categories_df to get the details of these categories\n",
    "            return categories_df[categories_df['id'].isin(assigned_category_ids)]\n",
    "\n",
    "    def getAreasAssignedToCategories(self, categories: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a DataFrame containing all the areas assigned to particular categories specified as input,\n",
    "        with no repetitions. If the input collection of categories is empty, it considers all categories.\n",
    "\n",
    "        Args:\n",
    "            categories (list): A list of original category IDs (e.g., [\"cat_123\", \"cat_456\"]).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame with columns 'id', 'name' for relevant areas.\n",
    "        \"\"\"\n",
    "        item_data_df = self._execute_query(\"SELECT * FROM item_data\")\n",
    "        categories_df = self._execute_query(\"SELECT id, original_id, quartile FROM categories\")\n",
    "        areas_df = self._execute_query(\"SELECT id, name FROM areas\")\n",
    "\n",
    "        if not categories:\n",
    "            # If no categories specified, get all areas that are linked to any item in item_data\n",
    "            all_area_ids_in_items = item_data_df['area'].dropna().unique().tolist()\n",
    "            \n",
    "            if not all_area_ids_in_items:\n",
    "                return pd.DataFrame(columns=[\"id\", \"name\"])\n",
    "\n",
    "            return areas_df[areas_df['id'].isin(all_area_ids_in_items)]\n",
    "        \n",
    "        else:\n",
    "            # Get internal category IDs for the given original category IDs\n",
    "            target_category_ids = categories_df[categories_df['original_id'].isin(categories)]['id'].tolist()\n",
    "\n",
    "            if not target_category_ids:\n",
    "                return pd.DataFrame(columns=[\"id\", \"name\"])\n",
    "\n",
    "            # Filter item_data to include only items assigned to the target categories\n",
    "            # This requires checking across all 8 category columns\n",
    "            category_mask = pd.Series([False] * len(item_data_df), index=item_data_df.index)\n",
    "            for i in range(1, 9):\n",
    "                col_name = f\"category_{i}\"\n",
    "                if col_name in item_data_df.columns:\n",
    "                    # Ensure that non-string IDs are handled (e.g., if internal IDs are numeric)\n",
    "                    # Convert target_category_ids to the same type as column or vice-versa if needed\n",
    "                    # For now, assuming they are consistent.\n",
    "                    category_mask = category_mask | item_data_df[col_name].isin(target_category_ids)\n",
    "            \n",
    "            filtered_item_data_df = item_data_df[category_mask]\n",
    "\n",
    "            if filtered_item_data_df.empty:\n",
    "                return pd.DataFrame(columns=[\"id\", \"name\"])\n",
    "\n",
    "            # Collect all unique area IDs from the filtered item_data\n",
    "            assigned_area_ids = filtered_item_data_df['area'].dropna().unique().tolist()\n",
    "            \n",
    "            if not assigned_area_ids:\n",
    "                return pd.DataFrame(columns=[\"id\", \"name\"])\n",
    "\n",
    "            # Filter the areas_df to get the details of these areas\n",
    "            return areas_df[areas_df['id'].isin(assigned_area_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Duplicate identifier '1608-8751' found for item at index 26775. Skipping item to maintain PK integrity.\n",
      "Data successfully uploaded to categories_database.db\n"
     ]
    }
   ],
   "source": [
    "handler = CategoryUploadHandler(\"categories_database.db\")\n",
    "handler.categoryUpload(\"scimago.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_id</th>\n",
       "      <th>quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, original_id, quartile]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = CategoryQueryHandler(\"categories_database.db\")\n",
    "query.getCategoriesWithQuartile(\"Q3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
