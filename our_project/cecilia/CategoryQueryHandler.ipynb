{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "import select\n",
    "from sqlite3 import connect\n",
    "from pandas import read_sql_query\n",
    "from json import load \n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from rdflib import Graph, URIRef, Literal, RDF \n",
    "from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Handler(object): #this is the first class, all the others derive from this one \n",
    "\n",
    "    #creating the class \n",
    "    def __init__(self, dbPathOrUrl : str):\n",
    "        self.dbPathOrUrl = dbPathOrUrl\n",
    "\n",
    "    #creating the methods \n",
    "    def getDbPathOrUrl(self): \n",
    "        return self.dbPathOrUrl \n",
    "\n",
    "    def setDbPathOrUrl(self, pathOrUrl : str): #: boolean \n",
    "        self.dbPathOrUrl = pathOrUrl\n",
    "        return True\n",
    "\n",
    "class UploadHandler(Handler):\n",
    "\n",
    "    def pushDataToDb(self, path: str):  #self implied \n",
    "        if path.lower().endswith(\".csv\"): \n",
    "            handler = JournalUploadHandler(self.dbPathOrUrl)\n",
    "            return handler.journalUpload(path) #calling the method after I called the subclass\n",
    "        elif path.lower().endswith(\".json\"): \n",
    "            handler = CategoryUploadHandler(self.dbPathOrUrl)\n",
    "            return handler.categoryUpload(path)\n",
    "        else: \n",
    "            return False \n",
    "\n",
    "#first case: the path is of the relational database the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codice da una sola tabella\n",
    "class CategoryUploadHandler(UploadHandler): \n",
    "    # TODO\n",
    "    # def __init__(self):\n",
    "    #     self.dbPathOrUrl = \"\"\n",
    "\n",
    "    def pushDataToDb(self, path: str): \n",
    "        \n",
    "        #creating the database \n",
    "        with connect(self.dbPathOrUrl) as con: \n",
    "            con.commit() #commit the current transactions to the database  \n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as c: \n",
    "            json_data = json.load(c) #reading the file \n",
    "\n",
    "            identifier_list = []\n",
    "\n",
    "            category_mapping_dict = {} #using it to keep track of what we have\n",
    "            categories_list = []\n",
    "\n",
    "            area_mapping_dict = {}\n",
    "            area_list = []\n",
    "\n",
    "            #internal identifier of all the items \n",
    "            for idx, item in enumerate(json_data): \n",
    "                item_internal_id = (\"item_\" + str(idx)) \n",
    "            \n",
    "                #1. creating internal ids for each element: identifiers \n",
    "                identifiers = item.get(\"identifiers\", []) #selecting the identifiers and using this method to retrive information from a dictionary and take into consideration the possibility that there is not an id \n",
    "\n",
    "                #iterating through the identifiers indise the bigger loop of items\n",
    "                for idx, row in enumerate(identifiers): #i use the iteration because there are more than one in some cases \n",
    "                    identifiers_internal_id = (item_internal_id) + (\"_identifier_internal_id_\") + str(idx) #thi is useful even if redundant because the iteration makes the indexes always restart, so we have many internal id which are 0 or 1 \n",
    "\n",
    "\n",
    "                    identifier_list.append({\n",
    "                            \"item_internal_id\": item_internal_id,\n",
    "                            # \"identifier_internal_id\": identifiers_internal_id,\n",
    "                            \"identifiers\": row #which is the single identifier \n",
    "                            })  #associating the data, with the internal id of the single category but also to the identifies of the whole item so that it's easier to query \n",
    "\n",
    "                #2. creating internal ids for the categories, this is trickier because they have more than one value and they can have same id\n",
    "                #i have to iterate thourg everything but check if the \"id\" is the same, so it's useful to use a dictionary \n",
    "                categories = item.get(\"categories\", []) #especially for category, quartile and area, that in the UML are noted as optional ([0...*]) it's better to do it this way \n",
    "\n",
    "                for row in categories: #appunto per me, scrivere cat_id = category[\"id\"] non ha senso perchè category è una lista di un dizionario, io devo internere come dizionario il singolo item \n",
    "                    cat_id = row.get(\"id\")\n",
    "\n",
    "                    if cat_id not in category_mapping_dict: #checking if the category is not already in the dictionary \n",
    "                        category_id_internal_id = (\"category_id_\") + str(len(category_mapping_dict))\n",
    "                        category_mapping_dict[cat_id] = (category_id_internal_id)\n",
    "                    else: \n",
    "                        category_id_internal_id = category_mapping_dict[cat_id] #if it's already inside the dict consider the original id \n",
    "\n",
    "                    #checking for the quartile, because it's optional in the UML\n",
    "                    quartile = row.get(\"quartile\", \"\")\n",
    "\n",
    "                    categories_list.append({\n",
    "                        \"item_internal_id\": item_internal_id,\n",
    "                        # \"category_internal_id\" : category_id_internal_id,\n",
    "                        \"category_id\": cat_id,\n",
    "                        \"category_quartile\": quartile\n",
    "                    })\n",
    "                \n",
    "            \n",
    "                #3. creating internal ids for areas, this is the same but without any more value \n",
    "                areas = item.get(\"areas\", [])\n",
    "\n",
    "                for area in areas: \n",
    "                    if area not in area_mapping_dict: \n",
    "                        area_id = ((\"area_id_\") + str(len(area_mapping_dict)))\n",
    "                        area_mapping_dict[area] = area_id\n",
    "                    else: \n",
    "                        area_id = area_mapping_dict[area]\n",
    "                \n",
    "                    area_list.append({\n",
    "                        \"item_internal_id\": item_internal_id, \n",
    "                        # \"area_internal_id\": area_id,\n",
    "                        \"area\": area\n",
    "                    })\n",
    "            \n",
    "            \n",
    "            #converting the data in dataframes \n",
    "            identifiers_df = pd.DataFrame(identifier_list)\n",
    "            categories_df = pd.DataFrame(categories_list)\n",
    "            areas_df = pd.DataFrame(area_list)\n",
    "            # unirle\n",
    "            merge_1 = pd.merge(identifiers_df, categories_df, left_on='item_internal_id', right_on='item_internal_id')\n",
    "            merge_2 = pd.merge(merge_1, areas_df, left_on='item_internal_id', right_on='item_internal_id')\n",
    "            \n",
    "\n",
    "        with connect(self.dbPathOrUrl) as con:\n",
    "            # identifiers_df.to_sql(\"identifiers\", con, if_exists=\"replace\", index=False)\n",
    "            # categories_df.to_sql(\"categories\", con, if_exists=\"replace\", index=False)\n",
    "            # areas_df.to_sql(\"areas\", con, if_exists=\"replace\", index=False)\n",
    "            merge_2.to_sql('info', con, if_exists='replace', index=False)\n",
    "\n",
    "                # TODO: why not 'con.commit()'\n",
    "            \n",
    "#second case: the path is the one of a graph database, the csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryHandler:\n",
    "    def __init__(self):\n",
    "        self.dbPathOrUrl = \"\"\n",
    "\n",
    "    def getDbPathOrUrl(self):\n",
    "        return self.dbPathOrUrl\n",
    "\n",
    "    def setDbPathOrUrl(self, path):\n",
    "        self.dbPathOrUrl = path\n",
    "\n",
    "    def getById(self, id):\n",
    "        \"\"\"\n",
    "        Questo metodo cerca un'entità identificabile per ID nel database.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Questo metodo deve essere implementato nelle sottoclassi.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryQueryHandler:\n",
    "\n",
    "    def __init__(self, dbPathOrUrl: str):\n",
    "    \n",
    "        self.dbPathOrUrl = dbPathOrUrl\n",
    "\n",
    "    def _execute_query(self, query: str, params: tuple = None):\n",
    "      \n",
    "        try:\n",
    "            with sqlite3.connect(self.dbPathOrUrl) as con:\n",
    "                if params:\n",
    "                    df = pd.read_sql_query(query, con, params=params)\n",
    "                else:\n",
    "                    df = pd.read_sql_query(query, con)\n",
    "                return df\n",
    "        except sqlite3.Error as e:\n",
    "            if \"no such table: info\" in str(e):\n",
    "                 print(f\"Database error: The table 'info' does not exist in {self.dbPathOrUrl}\")\n",
    "            else:\n",
    "                 print(f\"Database error during query execution: {e}\")\n",
    "           \n",
    "            # This part might need adjustment based on expected columns for each method caller\n",
    "            return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during query execution: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def getAllCategories(self):\n",
    "        \n",
    "        # Select distinct non-null category IDs from the 'info' table\n",
    "        query = \"SELECT DISTINCT category_id FROM info WHERE category_id IS NOT NULL\"\n",
    "        df = self._execute_query(query)\n",
    "        # Ensure correct column name if df is empty\n",
    "        if df.empty and 'category_id' not in df.columns:\n",
    "             return pd.DataFrame(columns=['category_id'])\n",
    "        return df\n",
    "\n",
    "    def getAllAreas(self):\n",
    "      \n",
    "        # Select distinct non-null areas from the 'info' table\n",
    "        query = \"SELECT DISTINCT area FROM info WHERE area IS NOT NULL\"\n",
    "        df = self._execute_query(query)\n",
    "        # Ensure correct column name if df is empty\n",
    "        if df.empty and 'area' not in df.columns:\n",
    "             return pd.DataFrame(columns=['area'])\n",
    "        return df\n",
    "\n",
    "    def getCategoriesWithQuartile(self, quartiles: list):\n",
    "        \n",
    "        if not quartiles:\n",
    "            # Return all distinct category/quartile pairs\n",
    "            query = \"SELECT DISTINCT category_id, category_quartile FROM info WHERE category_id IS NOT NULL\"\n",
    "            df = self._execute_query(query)\n",
    "        else:\n",
    "            # Build the WHERE clause carefully to handle different types and NULL\n",
    "            conditions = []\n",
    "            params = []\n",
    "            has_null_quartile_request = False\n",
    "\n",
    "            for q in quartiles:\n",
    "                if q is None or pd.isna(q):\n",
    "                    has_null_quartile_request = True\n",
    "                else:\n",
    "                    # Add placeholder for non-null quartiles\n",
    "                    conditions.append(\"category_quartile = ?\")\n",
    "                     # Convert to string for consistent comparison if quartiles can be numbers/strings\n",
    "                    params.append(str(q))\n",
    "\n",
    "            where_clause = \"\"\n",
    "            if conditions:\n",
    "                where_clause = \"(\" + \" OR \".join(conditions) + \")\"\n",
    "\n",
    "            if has_null_quartile_request:\n",
    "                if where_clause:\n",
    "                    where_clause += \" OR category_quartile IS NULL\"\n",
    "                else:\n",
    "                    where_clause = \"category_quartile IS NULL\"\n",
    "\n",
    "            # Construct the final query only if there's a valid where_clause\n",
    "            if not where_clause:\n",
    "                 # This case should ideally not be reached if quartiles list is not empty,\n",
    "                 # but as a safeguard return empty df matching schema.\n",
    "                 return pd.DataFrame(columns=['category_id', 'category_quartile'])\n",
    "\n",
    "            query = f\"\"\"\n",
    "                SELECT DISTINCT category_id, category_quartile\n",
    "                FROM info\n",
    "                WHERE category_id IS NOT NULL AND ({where_clause})\n",
    "            \"\"\"\n",
    "            df = self._execute_query(query, tuple(params))\n",
    "\n",
    "        # Ensure correct column names if df is empty\n",
    "        if df.empty and ('category_id' not in df.columns or 'category_quartile' not in df.columns):\n",
    "             return pd.DataFrame(columns=['category_id', 'category_quartile'])\n",
    "        return df\n",
    "\n",
    "\n",
    "    def getCategoriesAssignedToAreas(self, areas: list):\n",
    "        \n",
    "        if not areas:\n",
    "            # If no areas specified, get all distinct categories/quartiles\n",
    "            query = \"SELECT DISTINCT category_id, category_quartile FROM info WHERE category_id IS NOT NULL\"\n",
    "            df = self._execute_query(query)\n",
    "        else:\n",
    "            # Create placeholders for the areas in the IN clause\n",
    "            placeholders = ','.join('?' for _ in areas)\n",
    "            query = f\"\"\"\n",
    "                SELECT DISTINCT category_id, category_quartile\n",
    "                FROM info\n",
    "                WHERE area IN ({placeholders}) AND category_id IS NOT NULL\n",
    "            \"\"\"\n",
    "            df = self._execute_query(query, tuple(areas))\n",
    "\n",
    "        # Ensure correct column names if df is empty\n",
    "        if df.empty and ('category_id' not in df.columns or 'category_quartile' not in df.columns):\n",
    "             return pd.DataFrame(columns=['category_id', 'category_quartile'])\n",
    "        return df\n",
    "\n",
    "    def getAreasAssignedToCategories(self, categories: list) -> pd.DataFrame:\n",
    "        \n",
    "        if not categories:\n",
    "            # If no categories specified, get all distinct areas\n",
    "            query = \"SELECT DISTINCT area FROM info WHERE area IS NOT NULL\"\n",
    "            df = self._execute_query(query)\n",
    "        else:\n",
    "            # Create placeholders for the categories in the IN clause\n",
    "            placeholders = ','.join('?' for _ in categories)\n",
    "            query = f\"\"\"\n",
    "                SELECT DISTINCT area\n",
    "                FROM info\n",
    "                WHERE category_id IN ({placeholders}) AND area IS NOT NULL\n",
    "            \"\"\"\n",
    "            df = self._execute_query(query, tuple(categories))\n",
    "\n",
    "        # Ensure correct column name if df is empty\n",
    "        if df.empty and 'area' not in df.columns:\n",
    "             return pd.DataFrame(columns=['area'])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = CategoryUploadHandler(\"dummy_relational.db\")\n",
    "handler.pushDataToDb(\"scimago.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics, Econometrics and Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pharmacology, Toxicology and Pharmaceutics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Materials Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business, Management and Accounting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chemical Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Physics and Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Social Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Environmental Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Health Professions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Arts and Humanities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Neuroscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Agricultural and Biological Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Earth and Planetary Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Decision Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nursing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dentistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Veterinary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            area\n",
       "0                                       Medicine\n",
       "1                               Computer Science\n",
       "2   Biochemistry, Genetics and Molecular Biology\n",
       "3            Economics, Econometrics and Finance\n",
       "4     Pharmacology, Toxicology and Pharmaceutics\n",
       "5                                         Energy\n",
       "6                              Materials Science\n",
       "7            Business, Management and Accounting\n",
       "8                              Multidisciplinary\n",
       "9                           Chemical Engineering\n",
       "10                                   Engineering\n",
       "11                   Immunology and Microbiology\n",
       "12                                     Chemistry\n",
       "13                         Physics and Astronomy\n",
       "14                               Social Sciences\n",
       "15                         Environmental Science\n",
       "16                            Health Professions\n",
       "17                           Arts and Humanities\n",
       "18                                  Neuroscience\n",
       "19          Agricultural and Biological Sciences\n",
       "20                                    Psychology\n",
       "21                  Earth and Planetary Sciences\n",
       "22                                   Mathematics\n",
       "23                             Decision Sciences\n",
       "24                                       Nursing\n",
       "25                                     Dentistry\n",
       "26                                    Veterinary"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = CategoryQueryHandler(\"dummy_relational.db\")\n",
    "query.getAllAreas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
